#!/usr/bin/env python3
"""
ä»£ç ç´¢å¼•APIå®¢æˆ·ç«¯ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä»£ç ç´¢å¼•APIè¿›è¡Œæœç´¢ã€åˆ†æå’Œç¼–è¾‘æ“ä½œ
"""

import json
import os
import requests
import time
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Any

class CodeIndexAPIClient:
    def __init__(self, base_url="http://127.0.0.1:8080"):
        self.base_url = base_url
    
    def index_project(self, project_path, force=False, max_tokens=1000):
        """ç´¢å¼•é¡¹ç›®"""
        url = f"{self.base_url}/index"
        data = {
            "project_path": project_path,
            "force": force,
            "max_tokens": max_tokens
        }
        response = requests.post(url, json=data)
        return response.json()
    
    def search_code(self, query, project_path=None, top_k=10, language=None):
        """æœç´¢ä»£ç """
        url = f"{self.base_url}/search"
        data = {
            "query": query,
            "top_k": top_k
        }
        if project_path:
            data["project_path"] = project_path
        if language:
            data["language"] = language
        
        response = requests.post(url, json=data)
        return response.json()
    
    def get_context_from_search_results(self, search_results, project_path, max_results=3):
        """åŸºäºæœç´¢ç»“æœè·å–ä»£ç ä¸Šä¸‹æ–‡"""
        if not search_results.get('results'):
            return {'contexts': [], 'total_results': 0}
        
        contexts = []
        for i, result in enumerate(search_results['results'][:max_results]):
            try:
                file_path = Path(project_path) / result['file_path']
                if file_path.exists():
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                    
                    start_line = max(0, result['start_line'] - 1)
                    end_line = min(len(lines), result['end_line'])
                    code_content = ''.join(lines[start_line:end_line])
                    
                    context = {
                        'file_path': result['file_path'],
                        'start_line': result['start_line'],
                        'end_line': result['end_line'],
                        'similarity': result['similarity'],
                        'language': result['language'],
                        'chunk_type': result['chunk_type'],
                        'code_content': code_content.rstrip()
                    }
                    contexts.append(context)
                else:
                    contexts.append({
                        'file_path': result['file_path'],
                        'error': 'æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®'
                    })
            except Exception as e:
                contexts.append({
                    'file_path': result['file_path'],
                    'error': f'è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}'
                })
        
        return {
            'contexts': contexts,
            'total_results': len(search_results['results']),
            'displayed_results': len(contexts)
        }

    def get_context(self, query=None, project_path=None, max_chunks=5, search_results=None):
        """è·å–ä»£ç ä¸Šä¸‹æ–‡"""
        url = f"{self.base_url}/context"
        data = {
            "max_chunks": max_chunks
        }
        
        # æ·»åŠ å¯é€‰å‚æ•°
        if query:
            data["query"] = query
        if project_path:
            data["project_path"] = project_path
        if search_results:
            data["search_results"] = search_results
        
        response = requests.post(url, json=data)
        return response.json()
    
    def get_all_projects_status(self):
        """è·å–æ‰€æœ‰é¡¹ç›®çŠ¶æ€"""
        url = f"{self.base_url}/status"
        response = requests.get(url)
        return response.json()
    
    def get_project_status(self, project_path):
        """è·å–ç‰¹å®šé¡¹ç›®çŠ¶æ€"""
        url = f"{self.base_url}/status/{project_path}"
        response = requests.get(url)
        return response.json()
    
    def update_project(self, project_path):
        """æ›´æ–°é¡¹ç›®ç´¢å¼•"""
        url = f"{self.base_url}/update/{project_path}"
        response = requests.post(url)
        return response.json()
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        url = f"{self.base_url}/stats"
        response = requests.get(url)
        return response.json()
    
    def delete_project(self, project_path, confirm=True):
        """åˆ é™¤é¡¹ç›®ç´¢å¼•"""
        url = f"{self.base_url}/delete/{project_path}"
        params = {"confirm": confirm}
        response = requests.delete(url, params=params)
        return response.json()
    
    def cleanup_storage(self):
        """æ¸…ç†å­˜å‚¨ç©ºé—´"""
        url = f"{self.base_url}/cleanup"
        response = requests.post(url)
        return response.json()
    
    def get_config(self):
        """è·å–é…ç½®"""
        url = f"{self.base_url}/config"
        response = requests.get(url)
        return response.json()
    
    def set_config(self, key, value):
        """è®¾ç½®é…ç½®"""
        url = f"{self.base_url}/config"
        data = {"key": key, "value": value}
        response = requests.post(url, json=data)
        return response.json()
    
    # ==================== ä»£ç ç¼–è¾‘åŠŸèƒ½ ====================
    
    def search_and_analyze_edit(self, query, project_path=None, top_k=10, 
                               filter_language=None, filter_file_type=None, 
                               use_hybrid_search=True):
        """æœç´¢ä»£ç å¹¶ç›´æ¥åˆ†æè¯­ä¹‰ç¼–è¾‘è¯·æ±‚ - åˆå¹¶æ“ä½œé¿å…é‡å¤"""
        url = f"{self.base_url}/search_and_analyze_edit"
        data = {
            "query": query,
            "top_k": top_k,
            "use_hybrid_search": use_hybrid_search
        }
        if project_path:
            data["project_path"] = project_path
        if filter_language:
            data["filter_language"] = filter_language
        if filter_file_type:
            data["filter_file_type"] = filter_file_type
        
        response = requests.post(url, json=data)
        return response.json()
    
    def search_and_edit(self, query, project_path=None, top_k=10, 
                       filter_language=None, filter_file_type=None, 
                       use_hybrid_search=True, auto_apply=False, 
                       confidence_threshold=0.7, generate_patch=False):
        """æœç´¢ä»£ç å¹¶ç›´æ¥æ‰§è¡Œè¯­ä¹‰ç¼–è¾‘ - ä¸€ç«™å¼æ“ä½œ"""
        url = f"{self.base_url}/search_and_edit"
        data = {
            "query": query,
            "top_k": top_k,
            "use_hybrid_search": use_hybrid_search,
            "auto_apply": auto_apply,
            "confidence_threshold": confidence_threshold,
            "generate_patch": generate_patch
        }
        if project_path:
            data["project_path"] = project_path
        if filter_language:
            data["filter_language"] = filter_language
        if filter_file_type:
            data["filter_file_type"] = filter_file_type
        
        response = requests.post(url, json=data)
        return response.json()
    
    def analyze_code_modification(self, request, search_results=None, project_path=None):
        """åˆ†æä»£ç ä¿®æ”¹è¯·æ±‚ï¼Œç”Ÿæˆç¼–è¾‘è®¡åˆ’"""
        url = f"{self.base_url}/edit/analyze"
        data = {
            "request": request,
            "auto_apply": False  # åˆ†ææ—¶ä¸è‡ªåŠ¨åº”ç”¨
        }
        if search_results:
            data["search_results"] = search_results
        if project_path:
            data["project_path"] = project_path
        
        response = requests.post(url, json=data)
        return response.json()
    
    def apply_code_edit(self, request, search_results=None, project_path=None, auto_apply=True):
        """åº”ç”¨ä»£ç ç¼–è¾‘"""
        url = f"{self.base_url}/edit/apply"
        data = {
            "request": request,
            "auto_apply": auto_apply
        }
        if search_results:
            data["search_results"] = search_results
        if project_path:
            data["project_path"] = project_path
        
        response = requests.post(url, json=data)
        return response.json()
    
    def get_edit_history(self):
        """è·å–ç¼–è¾‘å†å²"""
        url = f"{self.base_url}/edit/history"
        response = requests.get(url)
        return response.json()
    
    def rollback_last_edit(self):
        """å›æ»šæœ€åä¸€æ¬¡ç¼–è¾‘"""
        url = f"{self.base_url}/edit/rollback"
        response = requests.post(url)
        return response.json()

    def apply_multiple_patches(self, patches: List[Dict[str, Any]], create_backup: bool = True):
        """æ‰¹é‡åº”ç”¨å¤šä¸ªå·®å¼‚è¡¥ä¸ - HTTP APIæ–¹å¼"""
        url = f"{self.base_url}/edit/apply_patches"
        data = {
            "patches": patches,
            "create_backup": create_backup
        }
        response = requests.post(url, json=data)
        return response.json()

    # ==================== æœ¬åœ°è¡¥ä¸åº”ç”¨åŠŸèƒ½ ====================
    
    def apply_patch_locally(self, patch_info: Dict[str, Any], create_backup: bool = True) -> Dict[str, Any]:
        """æœ¬åœ°åº”ç”¨å•ä¸ªå·®å¼‚è¡¥ä¸"""
        result = {
            'success': False,
            'file_path': patch_info['file_path'],
            'backup_path': None,
            'error': None
        }
        
        try:
            file_path = patch_info['file_path']
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                result['error'] = f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                return result
            
            # 1. åˆ›å»ºå¤‡ä»½
            if create_backup:
                backup_path = f"{file_path}.backup_{int(time.time())}"
                shutil.copy2(file_path, backup_path)
                result['backup_path'] = backup_path
                print(f"ğŸ“ åˆ›å»ºå¤‡ä»½æ–‡ä»¶: {backup_path}")
            
            # 2. è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                original_content = f.read()
            
            print(f"ğŸ“– è¯»å–åŸå§‹æ–‡ä»¶: {file_path}")
            print(f"åŸå§‹æ–‡ä»¶å¤§å°: {len(original_content)} å­—ç¬¦")
            
            # 3. åº”ç”¨å·®å¼‚è¡¥ä¸
            modified_content = self._apply_diff_to_content(original_content, patch_info['diff'])
            
            # 4. æ£€æŸ¥å†…å®¹æ˜¯å¦çœŸçš„å‘ç”Ÿäº†å˜åŒ–
            if modified_content == original_content:
                print("âš ï¸  è­¦å‘Š: åº”ç”¨è¡¥ä¸åå†…å®¹æ²¡æœ‰å˜åŒ–")
                # å°è¯•ä½¿ç”¨æ™ºèƒ½å·®å¼‚åº”ç”¨ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
                print("ğŸ”„ å°è¯•ä½¿ç”¨æ™ºèƒ½å·®å¼‚åº”ç”¨...")
                modified_content = self._apply_smart_diff(original_content, patch_info['diff'])
                
                if modified_content == original_content:
                    result['error'] = "å·®å¼‚è¡¥ä¸åº”ç”¨åå†…å®¹æ²¡æœ‰å˜åŒ–ï¼Œå¯èƒ½æ˜¯è¡¥ä¸æ ¼å¼é—®é¢˜"
                    return result
            
            # 5. å†™å…¥ä¿®æ”¹åçš„å†…å®¹
            with open(file_path, 'w', encoding='utf-8', newline='') as f:
                f.write(modified_content)
            
            print(f"ğŸ’¾ å†™å…¥ä¿®æ”¹åçš„æ–‡ä»¶: {file_path}")
            print(f"ä¿®æ”¹åæ–‡ä»¶å¤§å°: {len(modified_content)} å­—ç¬¦")
            
            # 6. éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„è¢«ä¿®æ”¹äº†
            with open(file_path, 'r', encoding='utf-8') as f:
                verification_content = f.read()
            
            if verification_content != original_content:
                result['success'] = True
                print(f"âœ… æˆåŠŸåº”ç”¨å·®å¼‚è¡¥ä¸åˆ°æ–‡ä»¶: {file_path}")
                print(f"å†…å®¹å˜åŒ–: {len(original_content)} -> {len(verification_content)} å­—ç¬¦")
            else:
                result['error'] = "æ–‡ä»¶å†™å…¥åéªŒè¯å¤±è´¥ï¼Œå†…å®¹æ²¡æœ‰å®é™…æ”¹å˜"
                print(f"âŒ æ–‡ä»¶å†™å…¥éªŒè¯å¤±è´¥: {file_path}")
            
        except Exception as e:
            result['error'] = str(e)
            print(f"âŒ åº”ç”¨å·®å¼‚è¡¥ä¸å¤±è´¥: {e}")
            
        return result
    
    def _apply_diff_to_content(self, original_content: str, diff_text: str) -> str:
        """å°†å·®å¼‚è¡¥ä¸åº”ç”¨åˆ°å†…å®¹ä¸Š"""
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨Pythonçš„difflibæ¥åº”ç”¨è¡¥ä¸
            if self._is_unified_diff(diff_text):
                return self._apply_unified_diff(original_content, diff_text)
            else:
                # å¯¹äºéæ ‡å‡†æ ¼å¼ï¼Œå°è¯•æ™ºèƒ½è§£æ
                return self._apply_smart_diff(original_content, diff_text)
            
        except Exception as e:
            print(f"å·®å¼‚è¡¥ä¸åº”ç”¨å¤±è´¥: {e}")
            print(f"å·®å¼‚å†…å®¹: {diff_text[:200]}...")
            return original_content
    
    def _is_unified_diff(self, diff_text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ ‡å‡†çš„unified diffæ ¼å¼"""
        return '@@' in diff_text and (diff_text.startswith('---') or '@@' in diff_text.split('\n')[0:3])
    
    def _apply_unified_diff(self, original_content: str, diff_text: str) -> str:
        """åº”ç”¨æ ‡å‡†çš„unified diffæ ¼å¼ï¼Œæ”¯æŒå¤šä¸ªhunkçš„æ™ºèƒ½å¤„ç†"""
        print("åº”ç”¨æ ‡å‡†unified diffæ ¼å¼")
        import re
        
        # ç¡®ä¿åŸå§‹å†…å®¹ä½¿ç”¨ç»Ÿä¸€çš„è¡Œç»“æŸç¬¦
        original_content = original_content.replace('\r\n', '\n').replace('\r', '\n')
        lines = original_content.splitlines(keepends=True)
        diff_lines = diff_text.splitlines()
        
        print(f"åŸå§‹æ–‡ä»¶è¡Œæ•°: {len(lines)}")
        print(f"å·®å¼‚è¡¥ä¸è¡Œæ•°: {len(diff_lines)}")
        
        # ğŸ”§ ä¼˜åŒ–ï¼šè§£ææ‰€æœ‰hunkï¼Œç„¶åä»ä¸‹å¾€ä¸Šåº”ç”¨
        hunks = []
        i = 0
        while i < len(diff_lines):
            line = diff_lines[i]
            
            if line.startswith('@@'):
                # è§£æhunkå¤´éƒ¨ @@-start,count +start,count@@
                match = re.match(r'@@\s*-(\d+)(?:,(\d+))?\s*\+(\d+)(?:,(\d+))?\s*@@', line)
                if match:
                    old_start = int(match.group(1)) - 1  # è½¬æ¢ä¸º0ç´¢å¼•
                    old_count = int(match.group(2)) if match.group(2) else 1
                    new_start = int(match.group(3)) - 1  # è½¬æ¢ä¸º0ç´¢å¼•
                    new_count = int(match.group(4)) if match.group(4) else 1
                    
                    # æ”¶é›†hunkå†…å®¹
                    hunk_lines = []
                    i += 1
                    while i < len(diff_lines) and not diff_lines[i].startswith('@@'):
                        hunk_lines.append(diff_lines[i])
                        i += 1
                    
                    hunks.append({
                        'old_start': old_start,
                        'old_count': old_count,
                        'new_start': new_start,
                        'new_count': new_count,
                        'lines': hunk_lines
                    })
                    continue
            
            i += 1
        
        # ğŸ”§ å…³é”®ä¼˜åŒ–ï¼šæŒ‰old_startä»å¤§åˆ°å°æ’åºï¼Œä»ä¸‹å¾€ä¸Šåº”ç”¨
        hunks.sort(key=lambda h: h['old_start'], reverse=True)
        
        print(f"è§£æåˆ° {len(hunks)} ä¸ªhunkï¼Œå°†ä»ä¸‹å¾€ä¸Šåº”ç”¨:")
        for idx, hunk in enumerate(hunks):
            print(f"  Hunk {idx+1}: è¡Œ{hunk['old_start']+1}-{hunk['old_start']+hunk['old_count']}")
        
        result_lines = lines[:]  # å¤åˆ¶åŸå§‹è¡Œ
        
        # ä»ä¸‹å¾€ä¸Šåº”ç”¨æ¯ä¸ªhunk
        for hunk_idx, hunk in enumerate(hunks):
            print(f"\nåº”ç”¨ Hunk {hunk_idx+1}/{len(hunks)}: è¡Œ{hunk['old_start']+1}-{hunk['old_start']+hunk['old_count']}")
            
            old_start = hunk['old_start']
            old_count = hunk['old_count']
            hunk_lines = hunk['lines']
            
            # æ„å»ºæ–°çš„è¡Œå†…å®¹
            new_lines = []
            hunk_line_idx = 0
            original_lines_processed = 0
            
            while hunk_line_idx < len(hunk_lines):
                hunk_line = hunk_lines[hunk_line_idx]
                
                if hunk_line.startswith(' '):
                    # ä¸Šä¸‹æ–‡è¡Œï¼Œä¿æŒä¸å˜
                    new_lines.append(hunk_line[1:])
                    if not hunk_line[1:].endswith('\n') and len(result_lines) > 0 and result_lines[0].endswith('\n'):
                        new_lines[-1] += '\n'
                    original_lines_processed += 1
                elif hunk_line.startswith('-'):
                    # åˆ é™¤è¡Œï¼Œè·³è¿‡ï¼ˆä¸æ·»åŠ åˆ°new_linesï¼‰
                    print(f"  åˆ é™¤è¡Œ {old_start + original_lines_processed + 1}: {hunk_line[1:].strip()}")
                    original_lines_processed += 1
                elif hunk_line.startswith('+'):
                    # æ·»åŠ è¡Œ
                    new_line = hunk_line[1:]
                    if not new_line.endswith('\n') and len(result_lines) > 0 and result_lines[0].endswith('\n'):
                        new_line += '\n'
                    print(f"  æ·»åŠ è¡Œ: {new_line.strip()}")
                    new_lines.append(new_line)
                
                hunk_line_idx += 1
            
            # æ›¿æ¢åŸå§‹æ–‡ä»¶ä¸­çš„å¯¹åº”è¡Œ
            end_idx = old_start + old_count
            if end_idx > len(result_lines):
                end_idx = len(result_lines)
            
            print(f"  æ›¿æ¢è¡ŒèŒƒå›´: {old_start+1}-{end_idx} -> {len(new_lines)} è¡Œ")
            result_lines[old_start:end_idx] = new_lines
        
        result_content = ''.join(result_lines)
        print(f"\nâœ… å·®å¼‚åº”ç”¨å®Œæˆ:")
        print(f"  åŸå§‹å†…å®¹: {len(original_content)} å­—ç¬¦, {len(lines)} è¡Œ")
        print(f"  åº”ç”¨å: {len(result_content)} å­—ç¬¦, {len(result_lines)} è¡Œ")
        
        return result_content
    
    def _apply_smart_diff(self, original_content: str, diff_text: str) -> str:
        """æ™ºèƒ½åº”ç”¨éæ ‡å‡†æ ¼å¼çš„å·®å¼‚è¡¥ä¸"""
        print("æ­£åœ¨åº”ç”¨æ™ºèƒ½å·®å¼‚è¡¥ä¸...")
        try:
            # å°è¯•è§£æåŒ…å« +/- çš„ç®€å•å·®å¼‚æ ¼å¼
            diff_lines = diff_text.splitlines()
            original_lines = original_content.splitlines()
            
            # æŸ¥æ‰¾åˆ é™¤å’Œæ·»åŠ çš„è¡Œ
            lines_to_remove = []
            lines_to_add = []
            
            for line in diff_lines:
                if line.startswith('-'):
                    # åˆ é™¤è¡Œï¼ˆå»æ‰å‰ç¼€-ï¼‰
                    clean_line = line[1:].strip()
                    if clean_line:
                        lines_to_remove.append(clean_line)
                elif line.startswith('+'):
                    # æ·»åŠ è¡Œï¼ˆå»æ‰å‰ç¼€+ï¼‰
                    clean_line = line[1:]
                    lines_to_add.append(clean_line)
            
            # å¦‚æœæœ‰æ˜ç¡®çš„åˆ é™¤å’Œæ·»åŠ æ“ä½œ
            if lines_to_remove or lines_to_add:
                result_lines = []
                
                for original_line in original_lines:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ é™¤è¿™ä¸€è¡Œ
                    should_remove = False
                    for remove_line in lines_to_remove:
                        if remove_line in original_line:
                            should_remove = True
                            break
                    
                    if not should_remove:
                        result_lines.append(original_line)
                    else:
                        # å¦‚æœåˆ é™¤äº†ä¸€è¡Œï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æ·»åŠ è¡Œ
                        for add_line in lines_to_add:
                            if add_line not in result_lines:
                                result_lines.append(add_line)
                                lines_to_add.remove(add_line)
                                break
                
                # æ·»åŠ å‰©ä½™çš„æ–°è¡Œ
                result_lines.extend(lines_to_add)
                
                return '\n'.join(result_lines) + '\n' if original_content.endswith('\n') else '\n'.join(result_lines)
            
            # å¦‚æœæ— æ³•è§£æï¼Œå°è¯•ç›´æ¥æ–‡æœ¬æ›¿æ¢
            return self._apply_text_replacement(original_content, diff_text)
            
        except Exception as e:
            print(f"æ™ºèƒ½å·®å¼‚åº”ç”¨å¤±è´¥: {e}")
            return original_content
    
    def _apply_text_replacement(self, original_content: str, diff_text: str) -> str:
        """å°è¯•é€šè¿‡æ–‡æœ¬æ›¿æ¢åº”ç”¨å·®å¼‚"""
        try:
            # æŸ¥æ‰¾å¯èƒ½çš„æ›¿æ¢æ¨¡å¼
            lines = diff_text.splitlines()
            
            for i, line in enumerate(lines):
                if line.startswith('-') and i + 1 < len(lines) and lines[i + 1].startswith('+'):
                    # æ‰¾åˆ°æ›¿æ¢æ¨¡å¼ï¼š-old_text +new_text
                    old_text = line[1:].strip()
                    new_text = lines[i + 1][1:].strip()
                    
                    if old_text in original_content:
                        original_content = original_content.replace(old_text, new_text)
                        print(f"ğŸ”„ æ‰§è¡Œæ–‡æœ¬æ›¿æ¢: '{old_text[:50]}...' -> '{new_text[:50]}...'")
            
            return original_content
            
        except Exception as e:
            print(f"æ–‡æœ¬æ›¿æ¢å¤±è´¥: {e}")
            return original_content
    
    def interactive_apply_patches(self, patches: List[Dict[str, Any]], create_backup: bool = True) -> Dict[str, Any]:
        """äº¤äº’å¼åº”ç”¨å¤šä¸ªå·®å¼‚è¡¥ä¸ï¼Œç±»ä¼¼gitçš„äº¤äº’å¼æ¨¡å¼"""
        results = {
            'success': True,
            'applied_patches': [],
            'skipped_patches': [],
            'failed_patches': [],
            'backup_paths': []
        }
        
        print(f"\nğŸ” å‘ç° {len(patches)} ä¸ªå·®å¼‚è¡¥ä¸ï¼Œå¼€å§‹äº¤äº’å¼åº”ç”¨...")
        print("ğŸ“ æ“ä½œè¯´æ˜:")
        print("  y - åº”ç”¨æ­¤è¡¥ä¸")
        print("  n - è·³è¿‡æ­¤è¡¥ä¸") 
        print("  q - é€€å‡ºï¼Œä¸å†å¤„ç†åç»­è¡¥ä¸")
        print("  a - åº”ç”¨æ­¤è¡¥ä¸åŠæ‰€æœ‰åç»­è¡¥ä¸")
        print("  d - æ˜¾ç¤ºè¯¦ç»†å·®å¼‚å†…å®¹")
        print("  s - æ˜¾ç¤ºè¡¥ä¸ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 60)
        
        # ğŸ”§ ä¼˜åŒ–ï¼šæŒ‰æ–‡ä»¶åˆ†ç»„å¹¶æŒ‰è¡Œå·ä»å¤§åˆ°å°æ’åºï¼Œé¿å…è¡Œå·åç§»é—®é¢˜
        patches_by_file = {}
        for patch in patches:
            file_path = patch['file_path']
            if file_path not in patches_by_file:
                patches_by_file[file_path] = []
            patches_by_file[file_path].append(patch)
        
        # å¯¹æ¯ä¸ªæ–‡ä»¶çš„è¡¥ä¸æŒ‰è¡Œå·ä»å¤§åˆ°å°æ’åº
        for file_path in patches_by_file:
            patches_by_file[file_path].sort(
                key=lambda p: p.get('line_range', {}).get('start', 0), 
                reverse=True  # ä»ä¸‹å¾€ä¸Šåº”ç”¨
            )
        
        print(f"ğŸ“Š è¡¥ä¸åˆ†ç»„ç»Ÿè®¡:")
        for file_path, file_patches in patches_by_file.items():
            print(f"  ğŸ“„ {file_path}: {len(file_patches)} ä¸ªè¡¥ä¸")
        print("=" * 60)
        
        apply_all = False
        patch_index = 0
        
        # æŒ‰æ–‡ä»¶å¤„ç†è¡¥ä¸
        for file_path, file_patches in patches_by_file.items():
            print(f"\nğŸ“ å¤„ç†æ–‡ä»¶: {file_path}")
            print(f"ğŸ”¢ è¯¥æ–‡ä»¶å…±æœ‰ {len(file_patches)} ä¸ªè¡¥ä¸ï¼Œå°†ä»ä¸‹å¾€ä¸Šåº”ç”¨ä»¥é¿å…è¡Œå·åç§»")
            
            for i, patch in enumerate(file_patches):
                patch_index += 1
                if apply_all:
                    # è‡ªåŠ¨åº”ç”¨æ‰€æœ‰å‰©ä½™è¡¥ä¸
                    result = self.apply_patch_locally(patch, create_backup)
                    self._process_patch_result(result, results)
                    continue
                
                # æ˜¾ç¤ºè¡¥ä¸ä¿¡æ¯
                print(f"\nğŸ“„ è¡¥ä¸ {patch_index}/{len(patches)}: {patch['file_path']}")
                print(f"ğŸ”§ ç¼–è¾‘ç±»å‹: {patch.get('edit_type', 'unknown')}")
                print(f"ğŸ“Š ç½®ä¿¡åº¦: {patch.get('confidence', 0):.2f}")
                
                if 'line_range' in patch:
                    line_range = patch['line_range']
                    print(f"ğŸ“ è¡Œæ•°èŒƒå›´: {line_range.get('start', '?')}-{line_range.get('end', '?')}")
                    print(f"ğŸ”„ å¤„ç†é¡ºåº: æ–‡ä»¶å†…ç¬¬ {i+1}/{len(file_patches)} ä¸ªè¡¥ä¸ (ä»ä¸‹å¾€ä¸Š)")
                
                # æ˜¾ç¤ºç®€çŸ­çš„å·®å¼‚é¢„è§ˆ
                diff_lines = patch['diff'].splitlines()
                preview_lines = [line for line in diff_lines[:10] if line.strip()]
                if preview_lines:
                    print("ğŸ” å·®å¼‚é¢„è§ˆ:")
                    for line in preview_lines[:5]:
                        if line.startswith('+'):
                            print(f"  \033[32m{line}\033[0m")  # ç»¿è‰²
                        elif line.startswith('-'):
                            print(f"  \033[31m{line}\033[0m")  # çº¢è‰²
                        else:
                            print(f"  {line}")
                    if len(diff_lines) > 10:
                        print("  ... (æ›´å¤šå†…å®¹ï¼Œè¾“å…¥ 'd' æŸ¥çœ‹å®Œæ•´å·®å¼‚)")
                
                # è·å–ç”¨æˆ·é€‰æ‹©
                while True:
                    choice = input(f"\nåº”ç”¨æ­¤è¡¥ä¸? [y/n/q/a/d/s]: ").strip().lower()
                    
                    if choice == 'y':
                        result = self.apply_patch_locally(patch, create_backup)
                        self._process_patch_result(result, results)
                        break
                    elif choice == 'n':
                        results['skipped_patches'].append(patch['file_path'])
                        print(f"â­ï¸  è·³è¿‡è¡¥ä¸: {patch['file_path']}")
                        break
                    elif choice == 'q':
                        print("ğŸ›‘ ç”¨æˆ·é€‰æ‹©é€€å‡º")
                        return results
                    elif choice == 'a':
                        print("ğŸš€ åº”ç”¨æ­¤è¡¥ä¸åŠæ‰€æœ‰åç»­è¡¥ä¸")
                        apply_all = True
                        result = self.apply_patch_locally(patch, create_backup)
                        self._process_patch_result(result, results)
                        break
                    elif choice == 'd':
                        print("\nğŸ“‹ å®Œæ•´å·®å¼‚å†…å®¹:")
                        print("-" * 50)
                        for line in patch['diff'].splitlines():
                            if line.startswith('+'):
                                print(f"\033[32m{line}\033[0m")  # ç»¿è‰²
                            elif line.startswith('-'):
                                print(f"\033[31m{line}\033[0m")  # çº¢è‰²
                            else:
                                print(line)
                        print("-" * 50)
                    elif choice == 's':
                        self._show_patch_stats(patch)
                    else:
                        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ y/n/q/a/d/s")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        self._show_final_stats(results)
        return results
    
    def _process_patch_result(self, result: Dict[str, Any], results: Dict[str, Any]):
        """å¤„ç†å•ä¸ªè¡¥ä¸åº”ç”¨ç»“æœ"""
        if result['success']:
            results['applied_patches'].append(result['file_path'])
            if result['backup_path']:
                results['backup_paths'].append(result['backup_path'])
        else:
            results['failed_patches'].append({
                'file_path': result['file_path'],
                'error': result['error']
            })
            results['success'] = False
    
    def _show_patch_stats(self, patch: Dict[str, Any]):
        """æ˜¾ç¤ºè¡¥ä¸ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“Š è¡¥ä¸ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ–‡ä»¶è·¯å¾„: {patch['file_path']}")
        print(f"  ç¼–è¾‘ç±»å‹: {patch.get('edit_type', 'unknown')}")
        print(f"  ç½®ä¿¡åº¦: {patch.get('confidence', 0):.2f}")
        
        # åˆ†æå·®å¼‚å†…å®¹
        diff_lines = patch['diff'].splitlines()
        add_count = len([l for l in diff_lines if l.startswith('+')])
        del_count = len([l for l in diff_lines if l.startswith('-')])
        context_count = len([l for l in diff_lines if l.startswith(' ')])
        
        print(f"  æ·»åŠ è¡Œæ•°: {add_count}")
        print(f"  åˆ é™¤è¡Œæ•°: {del_count}")
        print(f"  ä¸Šä¸‹æ–‡è¡Œæ•°: {context_count}")
        
        if 'line_range' in patch:
            line_range = patch['line_range']
            print(f"  å½±å“è¡ŒèŒƒå›´: {line_range.get('start', '?')}-{line_range.get('end', '?')}")
    
    def _show_final_stats(self, results: Dict[str, Any]):
        """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“ˆ åº”ç”¨ç»“æœç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸåº”ç”¨: {len(results['applied_patches'])} ä¸ª")
        print(f"  â­ï¸  è·³è¿‡: {len(results['skipped_patches'])} ä¸ª")
        print(f"  âŒ å¤±è´¥: {len(results['failed_patches'])} ä¸ª")
        
        if results['backup_paths']:
            print(f"  ğŸ“ å¤‡ä»½æ–‡ä»¶: {len(results['backup_paths'])} ä¸ª")
            for backup in results['backup_paths']:
                print(f"    - {backup}")
        
        if results['failed_patches']:
            print(f"  âŒ å¤±è´¥è¯¦æƒ…:")
            for failed in results['failed_patches']:
                print(f"    - {failed['file_path']}: {failed['error']}")


def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    client = CodeIndexAPIClient()
    
    # ç¤ºä¾‹é¡¹ç›®è·¯å¾„
    project_path = str(Path(__file__).parent / "test_html_project")
    
    try:
        print("=== ä»£ç ç´¢å¼•APIå®¢æˆ·ç«¯ç¤ºä¾‹ ===\n")
        
        # 1. ç´¢å¼•é¡¹ç›®
        print("1. ç´¢å¼•é¡¹ç›®...")
        result = client.index_project(project_path)
        print(f"ç´¢å¼•ç»“æœ: {json.dumps(result, indent=2, ensure_ascii=False)}\n")
        
        # 2. æœç´¢ä»£ç å¹¶åˆ†æè¯­ä¹‰ç¼–è¾‘ - åˆå¹¶æ“ä½œ
        print("2. æœç´¢ä»£ç å¹¶åˆ†æè¯­ä¹‰ç¼–è¾‘...")
        modification_request = "å»æ‰ä½¿ç”¨æ³¡æ²«è½´ç›¸å…³çš„è¿åŠ¨"
        
        # ä½¿ç”¨å·®å¼‚è¡¥ä¸æ¨¡å¼
        search_and_analysis_result = client.search_and_edit(
            query=modification_request,
            project_path=project_path,
            auto_apply=False,  # ä¸è‡ªåŠ¨åº”ç”¨
            generate_patch=True  # ç”Ÿæˆå·®å¼‚è¡¥ä¸
        )
        
        print(f"æœç´¢å’Œåˆ†æç»“æœ:")
        print(f"  - æœç´¢åˆ° {search_and_analysis_result.get('search_count', 0)} ä¸ªç»“æœ")
        print(f"  - åˆ†ææˆåŠŸ: {search_and_analysis_result.get('analysis_success', False)}")
        print(f"  - å·®å¼‚è¡¥ä¸æ•°é‡: {len(search_and_analysis_result.get('patches', []))}")
        
        # åº”ç”¨å·®å¼‚è¡¥ä¸
        if search_and_analysis_result.get('patches'):
            print(f"\n=== å‘ç° {len(search_and_analysis_result['patches'])} ä¸ªå·®å¼‚è¡¥ä¸ ===")
            
            # ä½¿ç”¨æœ¬åœ°äº¤äº’å¼è¡¥ä¸åº”ç”¨
            apply_result = client.interactive_apply_patches(
                search_and_analysis_result['patches'], 
                create_backup=True
            )
            
            print(f"\nğŸ‰ è¡¥ä¸åº”ç”¨å®Œæˆ! æˆåŠŸ: {len(apply_result.get('applied_patches', []))} ä¸ª")
        else:
            print("æ²¡æœ‰ç”Ÿæˆå·®å¼‚è¡¥ä¸")
        

        # 3. è·å–é¡¹ç›®çŠ¶æ€
        print("\n3. è·å–é¡¹ç›®çŠ¶æ€...")
        status_result = client.get_project_status(project_path)
        print(f"é¡¹ç›®çŠ¶æ€: {json.dumps(status_result, indent=2, ensure_ascii=False)}")
        
    except requests.exceptions.ConnectionError:
        print("é”™è¯¯: æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨ã€‚è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œã€‚")
        print("è¿è¡Œå‘½ä»¤: python start_server.py")
    except Exception as e:
        print(f"é”™è¯¯: {e}")

if __name__ == "__main__":
    main()